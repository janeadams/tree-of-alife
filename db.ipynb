{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "from utils.eda import *\n",
    "from utils.lineage import *\n",
    "from tinydb import table, TinyDB, Query, where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_paths(df):\n",
    "    print('Finding longest paths...')\n",
    "\n",
    "    pkl_path = 'pickles/longest_paths.pkl'\n",
    "\n",
    "    #if os.path.exists(pkl_path):\n",
    "        #print('Loading from pickle...')\n",
    "        #with open(pkl_path, 'rb') as f:\n",
    "            #longest_path = pickle.load(f)\n",
    "        #return longest_path\n",
    "\n",
    "    G = compute_network(df)\n",
    "\n",
    "    # Perform topological sort\n",
    "    topo_order = list(nx.topological_sort(G))\n",
    "    \n",
    "    # Initialize a dictionary to store the longest path length for each node\n",
    "    longest_paths = {node: (0, []) for node in G.nodes}\n",
    "\n",
    "    os.makedirs('data/paths', exist_ok=True)\n",
    "    \n",
    "    # Process nodes in topological order\n",
    "    for node in tqdm(topo_order):\n",
    "        current_length, current_path = longest_paths[node]\n",
    "        for successor in G.successors(node):\n",
    "            successor_length, successor_path = longest_paths[successor]\n",
    "            new_length = current_length + 1\n",
    "            if new_length > successor_length:\n",
    "                longest_paths[successor] = (new_length, current_path + [successor])\n",
    "\n",
    "        with open(f'data/paths/{node}.pkl', 'wb') as f:\n",
    "            pickle.dump(current_path + [successor], f)\n",
    "        \n",
    "\n",
    "    #with open('longest_paths.pkl', 'wb') as f:\n",
    "        #pickle.dump(longest_paths, f)\n",
    "    return #longest_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filepath = 'data/longest_paths.csv'\n",
    "if os.path.exists(df_filepath):\n",
    "    df = pd.read_csv(df_filepath)\n",
    "else:\n",
    "    df = load_sample('all')\n",
    "    df.head(5)\n",
    "    print('Computing network...')\n",
    "    longest_paths = find_longest_paths(df)\n",
    "    df['path_length'] = df['ID'].map(lambda x: longest_paths[x][0])\n",
    "    df.to_csv('data/longest_paths.csv', index=False)\n",
    "    \n",
    "longest_paths = find_longest_paths(df)\n",
    "df.sort_values('path_length', ascending=False).head(10)\n",
    "px.histogram(df, x='path_length', nbins=100, log_y=True, title='Distribution of Path Lengths').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_coordinates(df):\n",
    "\n",
    "    # Get the top 20% of the df by path length\n",
    "    df = df.head(int(0.2 * len(df)))\n",
    "\n",
    "    # Find the central path (longest path)\n",
    "    def lookup_path(node):\n",
    "        with open(f'data/paths/{node}.pkl', 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    _, central_path = lookup_path(df.iloc[0]['ID'])\n",
    "    num_nodes = len(central_path)\n",
    "    \n",
    "    # Assign coordinates to the central path\n",
    "    coordinates = {}\n",
    "    x_center = 0\n",
    "    z_center = 0\n",
    "    for i, node in enumerate(central_path):\n",
    "        coordinates[node] = (x_center, df.loc[df['ID'] == node, 'created'].values[0], z_center)\n",
    "    \n",
    "    # Splay out the branches using an L-system inspired approach\n",
    "    angle_increment = np.pi / 4\n",
    "    for _, path in longest_paths[1:]:\n",
    "        angle = 0\n",
    "        for node in path:\n",
    "            if node not in coordinates:\n",
    "                parent = next(pred for pred in G.predecessors(node) if pred in coordinates)\n",
    "                px, py, pz = coordinates[parent]\n",
    "                distance = 1  # Distance between nodes (can be adjusted)\n",
    "                x = px + distance * np.cos(angle)\n",
    "                z = pz + distance * np.sin(angle)\n",
    "                y = df.loc[df['ID'] == node, 'created'].values[0]\n",
    "                coordinates[node] = (x, y, z)\n",
    "                angle += angle_increment\n",
    "    \n",
    "    # Put coordinates back into the DataFrame\n",
    "    df['x'] = df['ID'].map(lambda x: coordinates[x][0])\n",
    "    df['y'] = df['ID'].map(lambda x: coordinates[x][1])\n",
    "    df['z'] = df['ID'].map(lambda x: coordinates[x][2])\n",
    "\n",
    "    df.to_csv('data/coordinates.csv', index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_coordinates(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
