{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import tqdm\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up folders\n",
    "import os\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "if not os.path.exists('figs'):\n",
    "    os.makedirs('figs')\n",
    "if not os.path.exists('pickles'):\n",
    "    os.makedirs('pickles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cached(filename):\n",
    "    if os.path.exists(filename):\n",
    "        return pd.read_pickle(filename)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>parent</th>\n",
       "      <th>created</th>\n",
       "      <th>lifeSpan</th>\n",
       "      <th>speed</th>\n",
       "      <th>maxEnergy</th>\n",
       "      <th>kidEnergy</th>\n",
       "      <th>sensors</th>\n",
       "      <th>ancestor</th>\n",
       "      <th>nkids</th>\n",
       "      <th>pgmDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>355</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  parent  created  lifeSpan  speed  maxEnergy  kidEnergy  sensors  \\\n",
       "0  355      12        0         2    2.0          3          4        5   \n",
       "1   82       2        0         2    2.0          4          1        5   \n",
       "2  100       2        0         2    2.0          3          1        5   \n",
       "3  108       2        0         2    2.0          3          1        5   \n",
       "4  114       2        0         2    2.0          3          1        5   \n",
       "\n",
       "   ancestor  nkids  pgmDeath  \n",
       "0       355      2        20  \n",
       "1        82      3        20  \n",
       "2       100      3        20  \n",
       "3       108      3        20  \n",
       "4       114      3        20  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/SummaryIndividuals.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tables\u001b[38;5;241m.\u001b[39mopen_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickles/G.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "with tables.open_file('pickles/G.h5', mode='w') as f:\n",
    "    pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34112456/34112456 [06:54<00:00, 82281.99it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx' has no attribute 'write_gpickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m         G\u001b[38;5;241m.\u001b[39madd_edge(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparent\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tables\u001b[38;5;241m.\u001b[39mopen_file(G_cache, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 9\u001b[0m         \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_gpickle\u001b[49m(G, f, protocol\u001b[38;5;241m=\u001b[39mpickle\u001b[38;5;241m.\u001b[39mHIGHEST_PROTOCOL)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading graph\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'networkx' has no attribute 'write_gpickle'"
     ]
    }
   ],
   "source": [
    "# Create a directed graph\n",
    "G_cache = 'pickles/G.h5'\n",
    "if not check_cached(G_cache):\n",
    "    print('Creating graph')\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in tqdm.tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        G.add_edge(row['parent'], row['ID'])\n",
    "    with tables.open_file(G_cache, mode='w') as f:\n",
    "        pickle.dump(G, f)\n",
    "else:\n",
    "    print('Loading graph')\n",
    "    with tables.open_file(G_cache, mode='r') as f:\n",
    "        G = nx.read_gpickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Find the longest path for each node\n",
    "def longest_path_length(G, node):\n",
    "    lengths = nx.single_source_dijkstra_path_length(G, node)\n",
    "    return max(lengths.values()) if lengths else 0\n",
    "\n",
    "path_cache = 'pickles/path_lengths.pkl'\n",
    "\n",
    "if check_cached(path_cache) is None:\n",
    "    print('Calculating path lengths')\n",
    "    path_lengths = {node: longest_path_length(G, node) for node in tqdm.tqdm(G.nodes)}\n",
    "    with tables.open_file(path_cache, mode='w') as f:\n",
    "        pickle.dump(path_lengths, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    print('Loading path lengths')\n",
    "    with tables.open_file(path_cache, mode='r') as f:\n",
    "        path_lengths = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Sort nodes by path length and select the top 10%\n",
    "top_10_cache = 'pickles/top_10_percent_nodes.pkl'\n",
    "\n",
    "if check_cached(top_10_cache) is None:\n",
    "    print('Sorting nodes')\n",
    "    sorted_nodes = sorted(path_lengths, key=path_lengths.get, reverse=True)\n",
    "    top_10_percent_length = int(len(sorted_nodes) * 0.1)\n",
    "    top_10_percent_nodes = set(sorted_nodes[:top_10_percent_length])\n",
    "    with tables.open_file(top_10_cache, mode='w') as f:\n",
    "        pickle.dump(top_10_percent_nodes, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    print('Loading nodes')\n",
    "    with tables.open_file(top_10_cache, mode='r') as f:\n",
    "        top_10_percent_nodes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Extract all nodes involved in these top 10% longest lineages\n",
    "def extract_lineage(G, node, extracted):\n",
    "    if node not in G:\n",
    "        extracted.add(node)\n",
    "        return\n",
    "    extracted.add(node)\n",
    "    for child in G.successors(node):\n",
    "        extract_lineage(G, child, extracted)\n",
    "\n",
    "lineage_cache = 'pickles/extracted_nodes.pkl'\n",
    "\n",
    "if check_cached(lineage_cache) is None:\n",
    "    print('Extracting lineages')\n",
    "    extracted_nodes = set()\n",
    "    for node in tqdm.tqdm(top_10_percent_nodes):\n",
    "        extract_lineage(G, node, extracted_nodes)\n",
    "    with tables.open_file(lineage_cache, mode='w') as f:\n",
    "        pickle.dump(extracted_nodes, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    print('Loading lineages')\n",
    "    with tables.open_file(lineage_cache, mode='r') as f:\n",
    "        extracted_nodes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cache = 'data/filtered.csv'\n",
    "\n",
    "if check_cached(filtered_cache) is not None:\n",
    "    print('Loading filtered data')\n",
    "    with tables.open_file(filtered_cache, mode='r') as f:\n",
    "        filtered_df = pd.read_csv(filtered_cache)\n",
    "else:\n",
    "    print('Creating filtered data')\n",
    "    filtered_df = df[df['ID'].isin(extracted_nodes)]\n",
    "    with tables.open_file(filtered_cache, mode='w') as f:\n",
    "        filtered_df.write_csv(filtered_cache, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
